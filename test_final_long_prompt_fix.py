#!/usr/bin/env python3
"""
æœ€ç»ˆé•¿promptä¿®å¤éªŒè¯è„šæœ¬
æµ‹è¯•çœŸæ­£ç»•è¿‡CLIP 77 tokené™åˆ¶çš„å®ç°
"""

import re
import time

def analyze_logs_for_truncation(log_file="logs"):
    """åˆ†ææ—¥å¿—ä¸­çš„æˆªæ–­é—®é¢˜"""
    print("ğŸ” åˆ†ææ—¥å¿—ä¸­çš„é•¿promptå¤„ç†...")
    
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŸ¥æ‰¾æˆªæ–­è­¦å‘Š
        truncation_warnings = []
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            if "Token indices sequence length is longer than" in line:
                truncation_warnings.append({
                    'line': i+1,
                    'content': line.strip(),
                    'context': lines[max(0, i-2):i+3]
                })
            elif "The following part of your input was truncated" in line:
                truncation_warnings.append({
                    'line': i+1, 
                    'content': line.strip(),
                    'type': 'truncation'
                })
        
        # æŸ¥æ‰¾é•¿promptå¤„ç†æ—¥å¿—
        long_prompt_logs = []
        for i, line in enumerate(lines):
            if "é•¿promptåˆ†ä¸º" in line and "æ®µå¤„ç†" in line:
                long_prompt_logs.append({
                    'line': i+1,
                    'content': line.strip(),
                    'context': lines[max(0, i-1):i+4]
                })
            elif "çœŸæ­£çš„åˆ†æ®µé•¿promptå¤„ç†å®Œæˆ" in line:
                long_prompt_logs.append({
                    'line': i+1,
                    'content': line.strip(),
                    'type': 'success'
                })
        
        print(f"\nğŸ“Š åˆ†æç»“æœ:")
        print(f"   æˆªæ–­è­¦å‘Š: {len([w for w in truncation_warnings if 'truncation' in w.get('type', '')])} æ¡")
        print(f"   Tokené•¿åº¦è­¦å‘Š: {len([w for w in truncation_warnings if 'truncation' not in w.get('type', '')])} æ¡")
        print(f"   é•¿promptå¤„ç†æ—¥å¿—: {len(long_prompt_logs)} æ¡")
        
        if truncation_warnings:
            print(f"\nâš ï¸  ä»ç„¶å‘ç°æˆªæ–­é—®é¢˜:")
            for i, warning in enumerate(truncation_warnings[:5]):  # åªæ˜¾ç¤ºå‰5æ¡
                print(f"   {i+1}. ç¬¬{warning['line']}è¡Œ: {warning['content'][:100]}...")
        
        if long_prompt_logs:
            print(f"\nâœ… é•¿promptå¤„ç†æ—¥å¿—:")
            for log in long_prompt_logs[-3:]:  # æ˜¾ç¤ºæœ€è¿‘3æ¡
                print(f"   - {log['content']}")
                
        # åˆ†ææœ€æ–°çš„å¤„ç†æ˜¯å¦æˆåŠŸ
        latest_success = None
        for log in reversed(long_prompt_logs):
            if log.get('type') == 'success':
                latest_success = log
                break
        
        if latest_success:
            print(f"\nğŸ‰ æœ€æ–°çš„é•¿promptå¤„ç†æˆåŠŸ: ç¬¬{latest_success['line']}è¡Œ")
            return True
        else:
            print(f"\nâŒ æœªå‘ç°æœ€æ–°çš„é•¿promptå¤„ç†æˆåŠŸæ—¥å¿—")
            return False
            
    except FileNotFoundError:
        print(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return False
    except Exception as e:
        print(f"âŒ åˆ†ææ—¥å¿—æ—¶å‡ºé”™: {e}")
        return False

def create_test_prompts():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„é•¿prompt"""
    
    prompts = {
        "medium": {
            "text": "masterpiece, best quality, 1boy, muscular, handsome, detailed eyes, perfect anatomy, high resolution, cinematic lighting, detailed background",
            "expected_tokens": 25
        },
        "long": {
            "text": "masterpiece, best quality, amazing quality, 4k, ultra detailed, 1boy, solo, male focus, bodybuilder, muscular, big pecs, bara, thick thighs, huge thighs, handsome face, detailed eyes, perfect anatomy, dramatic lighting, cinematic composition, high resolution, photorealistic, detailed background, intricate details, professional photography, studio lighting, depth of field, bokeh effect, vibrant colors, sharp focus, perfect skin texture, detailed facial features, expressive eyes, confident pose, dynamic angle, artistic composition",
            "expected_tokens": 85
        },
        "super_long": {
            "text": "masterpiece, best quality, amazing quality, 4k, ultra detailed, ultra high resolution, photorealistic, professional photography, 1boy, solo, male focus, bodybuilder, muscular male, big pecs, bara, thick thighs, huge thighs, broad shoulders, defined abs, handsome face, chiseled jawline, detailed eyes, expressive eyes, perfect anatomy, flawless skin, detailed skin texture, dramatic lighting, cinematic lighting, studio lighting, professional lighting setup, volumetric lighting, rim lighting, soft shadows, high contrast, cinematic composition, dynamic angle, low angle shot, heroic pose, confident expression, serene expression, detailed background, intricate details, architectural background, modern interior, luxurious setting, elegant furniture, glass windows, natural light, depth of field, bokeh effect, shallow depth of field, vibrant colors, rich colors, color grading, sharp focus, crystal clear, hyper detailed, ultra sharp, 8k resolution, award winning photography, magazine quality, commercial photography style, fashion photography, editorial style, fine art photography",
            "expected_tokens": 180
        }
    }
    
    return prompts

def estimate_tokens(text):
    """ä¼°ç®—tokenæ•°é‡"""
    # ç®€å•çš„tokenä¼°ç®—
    words = text.split()
    token_pattern = r'\w+|[^\w\s]'
    total_tokens = 0
    for word in words:
        tokens = len(re.findall(token_pattern, word.lower()))
        total_tokens += tokens
    return total_tokens

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æœ€ç»ˆé•¿promptä¿®å¤éªŒè¯")
    print("=" * 50)
    
    # 1. åˆ†æå½“å‰æ—¥å¿—çŠ¶æ€
    print("\n1ï¸âƒ£  åˆ†æå½“å‰æ—¥å¿—çŠ¶æ€")
    current_success = analyze_logs_for_truncation()
    
    # 2. åˆ›å»ºæµ‹è¯•prompts
    print("\n2ï¸âƒ£  æµ‹è¯•promptåˆ†æ")
    test_prompts = create_test_prompts()
    
    for name, prompt_info in test_prompts.items():
        actual_tokens = estimate_tokens(prompt_info["text"])
        expected_tokens = prompt_info["expected_tokens"]
        
        print(f"\nğŸ“ {name.upper()} Prompt:")
        print(f"   é•¿åº¦: {len(prompt_info['text'])} å­—ç¬¦")
        print(f"   é¢„æœŸtokens: {expected_tokens}")
        print(f"   å®é™…ä¼°ç®—: {actual_tokens} tokens")
        print(f"   éœ€è¦åˆ†æ®µ: {'æ˜¯' if actual_tokens > 75 else 'å¦'}")
        
        if actual_tokens > 75:
            segments_needed = (actual_tokens + 74) // 75
            print(f"   é¢„æœŸåˆ†æ®µæ•°: {segments_needed}")
    
    # 3. æ£€æŸ¥ä¿®å¤çŠ¶æ€
    print(f"\n3ï¸âƒ£  ä¿®å¤çŠ¶æ€æ£€æŸ¥")
    
    if current_success:
        print("âœ… å½“å‰æ—¥å¿—æ˜¾ç¤ºé•¿promptå¤„ç†æˆåŠŸ")
        print("ğŸ“ˆ å»ºè®®æµ‹è¯•ä»¥ä¸‹åœºæ™¯:")
        print("   - åŠ¨æ¼«æ¨¡å‹ + LoRA + è¶…é•¿prompt (180+ tokens)")
        print("   - çœŸäººæ¨¡å‹ + LoRA + é•¿prompt (100+ tokens)")
        print("   - éªŒè¯ä¸å†å‡ºç°æˆªæ–­è­¦å‘Š")
    else:
        print("âŒ å½“å‰æ—¥å¿—ä»æ˜¾ç¤ºæˆªæ–­é—®é¢˜")
        print("ğŸ”§ éœ€è¦éªŒè¯ä¿®å¤æ˜¯å¦æ­£ç¡®éƒ¨ç½²")
    
    # 4. ç”Ÿæˆæµ‹è¯•å»ºè®®
    print(f"\n4ï¸âƒ£  æµ‹è¯•å»ºè®®")
    print("ğŸ“‹ æ¨èæµ‹è¯•æ­¥éª¤:")
    print("1. é‡å¯æœåŠ¡ç¡®ä¿æ–°ä»£ç ç”Ÿæ•ˆ")
    print("2. ä½¿ç”¨super_long promptæµ‹è¯•åŠ¨æ¼«æ¨¡å‹+LoRA")
    print("3. æ£€æŸ¥æ—¥å¿—æ˜¯å¦å‡ºç° 'çœŸæ­£çš„åˆ†æ®µé•¿promptå¤„ç†å®Œæˆ'")
    print("4. éªŒè¯ä¸å†æœ‰ 'truncated because CLIP' è­¦å‘Š")
    print("5. ç¡®è®¤ç”Ÿæˆçš„å›¾åƒè´¨é‡æ­£å¸¸")
    
    print(f"\nğŸ¯ å…³é”®æˆåŠŸæŒ‡æ ‡:")
    print("- æ— æˆªæ–­è­¦å‘Šæ¶ˆæ¯")
    print("- æ˜¾ç¤º 'ç»•è¿‡77 tokené™åˆ¶' æ—¥å¿—")
    print("- å›¾åƒæ–‡ä»¶å¤§å°æ­£å¸¸ (>1MB)")
    print("- ç”Ÿæˆé€Ÿåº¦æ­£å¸¸")

if __name__ == "__main__":
    main() 