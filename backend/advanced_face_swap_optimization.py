#!/usr/bin/env python3
"""
é«˜çº§æ¢è„¸ä¼˜åŒ–æ¨¡å— - è§£å†³CUDAå…¼å®¹æ€§ã€åŠ¨æ€æ··åˆã€é«˜ç²¾åº¦æ£€æµ‹ç­‰é—®é¢˜
Advanced Face Swap Optimization Module
"""

import os
import cv2
import numpy as np
import torch
from typing import Optional, Tuple, List, Dict, Any
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AdvancedFaceSwapOptimizer:
    """é«˜çº§æ¢è„¸ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.face_analyser = None
        self.face_swapper = None
        self.face_enhancer = None
        self.execution_providers = self._get_optimized_execution_providers()
        
    def _get_optimized_execution_providers(self) -> List[Any]:
        """è·å–ä¼˜åŒ–çš„æ‰§è¡Œæä¾›ç¨‹åºï¼Œè§£å†³CUDAå…¼å®¹æ€§é—®é¢˜"""
        providers = []
        
        if torch.cuda.is_available():
            try:
                import onnxruntime as ort
                available_providers = ort.get_available_providers()
                
                if 'CUDAExecutionProvider' in available_providers:
                    logger.info("ğŸ” Testing CUDA provider compatibility...")
                    
                    try:
                        # é…ç½®CUDAæä¾›ç¨‹åºé€‰é¡¹
                        cuda_options = {
                            'device_id': 0,
                            'arena_extend_strategy': 'kNextPowerOfTwo',
                            'gpu_mem_limit': 4 * 1024 * 1024 * 1024,  # 4GB
                            'cudnn_conv_algo_search': 'EXHAUSTIVE',
                            'do_copy_in_default_stream': True,
                        }
                        
                        # æ·»åŠ CUDAæä¾›ç¨‹åº
                        providers.append(('CUDAExecutionProvider', cuda_options))
                        logger.info("âœ… CUDA provider configured")
                        
                    except Exception as cuda_error:
                        logger.warning(f"âš ï¸ CUDA provider test failed: {cuda_error}")
                        logger.warning("âš ï¸ Falling back to CPU provider")
                        
                else:
                    logger.warning("âš ï¸ CUDA provider not available in onnxruntime")
                    
            except ImportError:
                logger.warning("âš ï¸ onnxruntime not available")
            except Exception as e:
                logger.warning(f"âš ï¸ ONNX Runtime setup failed: {e}")
        else:
            logger.warning("âš ï¸ CUDA not available, using CPU provider")
        
        # æ€»æ˜¯æ·»åŠ CPUä½œä¸ºå›é€€
        providers.append('CPUExecutionProvider')
        
        logger.info(f"ğŸ“ Final execution providers: {[p[0] if isinstance(p, tuple) else p for p in providers]}")
        return providers
    
    def init_enhanced_face_analyser(self) -> Optional[Any]:
        """åˆå§‹åŒ–å¢å¼ºçš„äººè„¸åˆ†æå™¨"""
        if self.face_analyser is not None:
            return self.face_analyser
            
        try:
            import insightface
            
            # å°è¯•ä½¿ç”¨æ›´é«˜ç²¾åº¦çš„buffalo_scæ¨¡å‹
            model_paths = [
                "/runpod-volume/faceswap/buffalo_sc",  # é«˜ç²¾åº¦æ¨¡å‹
                "/runpod-volume/faceswap/buffalo_l",   # æ ‡å‡†æ¨¡å‹
            ]
            
            for model_path in model_paths:
                if os.path.exists(model_path):
                    try:
                        model_name = os.path.basename(model_path)
                        logger.info(f"ğŸ” Trying face analysis model: {model_name}")
                        
                        self.face_analyser = insightface.app.FaceAnalysis(
                            name=model_name,
                            root=os.path.dirname(model_path),
                            providers=self.execution_providers
                        )
                        
                        # ä½¿ç”¨æ›´é«˜åˆ†è¾¨ç‡è¿›è¡Œæ£€æµ‹
                        det_size = (1280, 1280) if model_name == 'buffalo_sc' else (1024, 1024)
                        self.face_analyser.prepare(ctx_id=0, det_size=det_size)
                        
                        logger.info(f"âœ… Enhanced face analyser initialized with {model_name} (resolution: {det_size})")
                        return self.face_analyser
                        
                    except Exception as e:
                        logger.warning(f"âš ï¸ Failed to load {model_name}: {e}")
                        continue
            
            logger.error("âŒ No compatible face analysis model found")
            return None
            
        except ImportError:
            logger.error("âŒ InsightFace not available")
            return None
        except Exception as e:
            logger.error(f"âŒ Face analyser initialization failed: {e}")
            return None
    
    def calculate_dynamic_blend_ratio(self, source_face: Any, target_face: Any, 
                                    source_image: np.ndarray, target_image: np.ndarray) -> float:
        """æ ¹æ®çš®è‚¤è‰²å·®å’Œå…‰ç…§æ¡ä»¶åŠ¨æ€è®¡ç®—æ··åˆæ¯”ä¾‹"""
        try:
            # æå–äººè„¸åŒºåŸŸ
            source_bbox = source_face.bbox.astype(int)
            target_bbox = target_face.bbox.astype(int)
            
            source_face_region = source_image[source_bbox[1]:source_bbox[3], source_bbox[0]:source_bbox[2]]
            target_face_region = target_image[target_bbox[1]:target_bbox[3], target_bbox[0]:target_bbox[2]]
            
            # è®¡ç®—å¹³å‡é¢œè‰²
            source_mean_color = np.mean(source_face_region, axis=(0, 1))
            target_mean_color = np.mean(target_face_region, axis=(0, 1))
            
            # è®¡ç®—é¢œè‰²å·®å¼‚
            color_diff = np.linalg.norm(source_mean_color - target_mean_color)
            
            # è®¡ç®—å…‰ç…§å·®å¼‚
            source_brightness = np.mean(cv2.cvtColor(source_face_region, cv2.COLOR_BGR2GRAY))
            target_brightness = np.mean(cv2.cvtColor(target_face_region, cv2.COLOR_BGR2GRAY))
            brightness_diff = abs(source_brightness - target_brightness)
            
            # åŠ¨æ€è°ƒæ•´æ··åˆæ¯”ä¾‹
            base_ratio = 0.85
            
            # é¢œè‰²å·®å¼‚è¶Šå¤§ï¼Œæ··åˆæ¯”ä¾‹è¶Šä½
            color_adjustment = min(color_diff / 100.0, 0.15)
            
            # å…‰ç…§å·®å¼‚è¶Šå¤§ï¼Œæ··åˆæ¯”ä¾‹è¶Šä½
            brightness_adjustment = min(brightness_diff / 50.0, 0.1)
            
            dynamic_ratio = base_ratio - color_adjustment - brightness_adjustment
            dynamic_ratio = max(0.6, min(0.95, dynamic_ratio))
            
            logger.info(f"ğŸ¨ Dynamic blend ratio: {dynamic_ratio:.3f}")
            return dynamic_ratio
            
        except Exception as e:
            logger.warning(f"âš ï¸ Dynamic blend calculation failed: {e}")
            return 0.85
    
    def init_face_swapper(self) -> Optional[Any]:
        """åˆå§‹åŒ–æ¢è„¸æ¨¡å‹"""
        if self.face_swapper is not None:
            return self.face_swapper
            
        try:
            import insightface
            
            model_path = "/runpod-volume/faceswap/inswapper_128_fp16.onnx"
            if not os.path.exists(model_path):
                logger.error(f"âŒ Face swap model not found: {model_path}")
                return None
            
            self.face_swapper = insightface.model_zoo.get_model(
                model_path,
                providers=self.execution_providers
            )
            
            logger.info("âœ… Face swapper initialized successfully")
            return self.face_swapper
            
        except Exception as e:
            logger.error(f"âŒ Face swapper initialization failed: {e}")
            return None
    
    def init_face_enhancer(self) -> Optional[Any]:
        """åˆå§‹åŒ–è„¸éƒ¨å¢å¼ºå™¨"""
        if self.face_enhancer is not None:
            return self.face_enhancer
            
        try:
            from gfpgan import GFPGANer
            
            model_path = "/runpod-volume/faceswap/GFPGANv1.4.pth"
            if not os.path.exists(model_path):
                logger.error(f"âŒ GFPGAN model not found: {model_path}")
                return None
            
            self.face_enhancer = GFPGANer(
                model_path=model_path,
                upscale=1,
                arch='clean',
                channel_multiplier=2,
                bg_upsampler=None,
                device='cuda' if torch.cuda.is_available() else 'cpu'
            )
            
            logger.info("âœ… Face enhancer initialized successfully")
            return self.face_enhancer
            
        except Exception as e:
            logger.error(f"âŒ Face enhancer initialization failed: {e}")
            return None
    
    def detect_faces_multi_scale(self, image: np.ndarray) -> List[Any]:
        """å¤šå°ºåº¦äººè„¸æ£€æµ‹ï¼Œæé«˜æ£€æµ‹ç²¾åº¦"""
        if self.face_analyser is None:
            self.init_enhanced_face_analyser()
            
        if self.face_analyser is None:
            return []
        
        all_faces = []
        
        # å¤šå°ºåº¦æ£€æµ‹
        scales = [1.0, 1.2, 0.8]  # åŸå§‹å°ºå¯¸ã€æ”¾å¤§ã€ç¼©å°
        
        for scale in scales:
            try:
                if scale != 1.0:
                    h, w = image.shape[:2]
                    new_h, new_w = int(h * scale), int(w * scale)
                    scaled_image = cv2.resize(image, (new_w, new_h))
                else:
                    scaled_image = image
                
                faces = self.face_analyser.get(scaled_image)
                
                # å¦‚æœæ˜¯ç¼©æ”¾å›¾åƒï¼Œéœ€è¦è°ƒæ•´åæ ‡
                if scale != 1.0:
                    for face in faces:
                        face.bbox = face.bbox / scale
                        if hasattr(face, 'kps'):
                            face.kps = face.kps / scale
                
                all_faces.extend(faces)
                
            except Exception as e:
                logger.warning(f"âš ï¸ Multi-scale detection failed at scale {scale}: {e}")
                continue
        
        # å»é‡ï¼šç§»é™¤é‡å çš„æ£€æµ‹ç»“æœ
        unique_faces = self._remove_duplicate_faces(all_faces)
        
        logger.info(f"ğŸ” Multi-scale detection found {len(unique_faces)} unique faces")
        return unique_faces
    
    def _remove_duplicate_faces(self, faces: List[Any], iou_threshold: float = 0.5) -> List[Any]:
        """ç§»é™¤é‡å¤çš„äººè„¸æ£€æµ‹ç»“æœ"""
        if len(faces) <= 1:
            return faces
        
        # è®¡ç®—æ‰€æœ‰äººè„¸å¯¹çš„IoU
        unique_faces = []
        
        for i, face in enumerate(faces):
            is_duplicate = False
            
            for unique_face in unique_faces:
                iou = self._calculate_bbox_iou(face.bbox, unique_face.bbox)
                if iou > iou_threshold:
                    # ä¿ç•™ç½®ä¿¡åº¦æ›´é«˜çš„
                    if face.det_score > unique_face.det_score:
                        unique_faces.remove(unique_face)
                        unique_faces.append(face)
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_faces.append(face)
        
        return unique_faces
    
    def _calculate_bbox_iou(self, bbox1: np.ndarray, bbox2: np.ndarray) -> float:
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoU"""
        x1_min, y1_min, x1_max, y1_max = bbox1
        x2_min, y2_min, x2_max, y2_max = bbox2
        
        # è®¡ç®—äº¤é›†
        inter_x_min = max(x1_min, x2_min)
        inter_y_min = max(y1_min, y2_min)
        inter_x_max = min(x1_max, x2_max)
        inter_y_max = min(y1_max, y2_max)
        
        if inter_x_max <= inter_x_min or inter_y_max <= inter_y_min:
            return 0.0
        
        inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)
        
        # è®¡ç®—å¹¶é›†
        area1 = (x1_max - x1_min) * (y1_max - y1_min)
        area2 = (x2_max - x2_min) * (y2_max - y2_min)
        union_area = area1 + area2 - inter_area
        
        return inter_area / union_area if union_area > 0 else 0.0
    
    def apply_region_aware_blending(self, swapped_face: np.ndarray, original_face: np.ndarray, 
                                  face_landmarks: np.ndarray) -> np.ndarray:
        """åŒºåŸŸæ„ŸçŸ¥èåˆï¼šå¯¹ä¸åŒé¢éƒ¨åŒºåŸŸä½¿ç”¨ä¸åŒçš„èåˆå‚æ•°"""
        try:
            # å®šä¹‰é¢éƒ¨åŒºåŸŸ
            regions = {
                'forehead': [17, 18, 19, 20, 21, 22, 23, 24, 25, 26],  # é¢å¤´åŒºåŸŸ
                'cheeks': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],  # è„¸é¢Šè½®å»“
                'nose': [27, 28, 29, 30, 31, 32, 33, 34, 35],  # é¼»å­
                'eyes': [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],  # çœ¼éƒ¨
                'mouth': [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]  # å˜´éƒ¨
            }
            
            # ä¸åŒåŒºåŸŸçš„æ··åˆæƒé‡
            region_weights = {
                'forehead': 0.7,   # é¢å¤´ä¿ç•™æ›´å¤šåŸå§‹ç‰¹å¾
                'cheeks': 0.85,    # è„¸é¢Šä¸­ç­‰æ··åˆ
                'nose': 0.9,       # é¼»å­æ›´å¤šæ¢è„¸ç‰¹å¾
                'eyes': 0.95,      # çœ¼éƒ¨æœ€å¤šæ¢è„¸ç‰¹å¾
                'mouth': 0.9       # å˜´éƒ¨æ›´å¤šæ¢è„¸ç‰¹å¾
            }
            
            result = swapped_face.copy()
            h, w = result.shape[:2]
            
            for region_name, landmark_indices in regions.items():
                if len(landmark_indices) == 0:
                    continue
                    
                try:
                    # è·å–åŒºåŸŸå…³é”®ç‚¹
                    region_points = face_landmarks[landmark_indices]
                    
                    # åˆ›å»ºåŒºåŸŸæ©ç 
                    mask = np.zeros((h, w), dtype=np.uint8)
                    hull = cv2.convexHull(region_points.astype(np.int32))
                    cv2.fillPoly(mask, [hull], 255)
                    
                    # åº”ç”¨é«˜æ–¯æ¨¡ç³Šä½¿è¾¹ç•Œå¹³æ»‘
                    mask = cv2.GaussianBlur(mask, (15, 15), 0)
                    mask = mask.astype(np.float32) / 255.0
                    
                    # è·å–åŒºåŸŸæƒé‡
                    weight = region_weights.get(region_name, 0.85)
                    
                    # åŒºåŸŸæ··åˆ
                    for c in range(3):
                        result[:, :, c] = (
                            swapped_face[:, :, c] * mask * weight +
                            original_face[:, :, c] * mask * (1 - weight) +
                            result[:, :, c] * (1 - mask)
                        )
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ Region blending failed for {region_name}: {e}")
                    continue
            
            logger.info("âœ¨ Applied region-aware blending")
            return result.astype(np.uint8)
            
        except Exception as e:
            logger.warning(f"âš ï¸ Region-aware blending failed: {e}")
            return swapped_face
    
    def apply_lighting_correction(self, source_image: np.ndarray, target_image: np.ndarray) -> np.ndarray:
        """å…‰ç…§åŒ¹é…ï¼šä½¿ç”¨è‰²è°ƒæ˜ å°„å¯¹é½æºè„¸ä¸ç›®æ ‡å›¾åƒå…‰ç…§"""
        try:
            # è½¬æ¢ä¸ºLABè‰²å½©ç©ºé—´è¿›è¡Œå…‰ç…§åˆ†æ
            source_lab = cv2.cvtColor(source_image, cv2.COLOR_BGR2LAB)
            target_lab = cv2.cvtColor(target_image, cv2.COLOR_BGR2LAB)
            
            # åˆ†ç¦»äº®åº¦é€šé“
            source_l = source_lab[:, :, 0]
            target_l = target_lab[:, :, 0]
            
            # è®¡ç®—äº®åº¦ç»Ÿè®¡
            source_mean = np.mean(source_l)
            target_mean = np.mean(target_l)
            source_std = np.std(source_l)
            target_std = np.std(target_l)
            
            # äº®åº¦åŒ¹é…
            if source_std > 0:
                adjusted_l = (source_l - source_mean) * (target_std / source_std) + target_mean
                adjusted_l = np.clip(adjusted_l, 0, 255)
                
                # é‡æ–°ç»„åˆLABå›¾åƒ
                adjusted_lab = source_lab.copy()
                adjusted_lab[:, :, 0] = adjusted_l
                
                # è½¬æ¢å›BGR
                result = cv2.cvtColor(adjusted_lab, cv2.COLOR_LAB2BGR)
                
                logger.info("âœ¨ Applied lighting correction")
                return result
            else:
                return source_image
                
        except Exception as e:
            logger.warning(f"âš ï¸ Lighting correction failed: {e}")
            return source_image
    
    def enhance_face_with_adaptive_strength(self, face_image: np.ndarray, 
                                          quality_score: float = 0.5) -> Tuple[np.ndarray, bool]:
        """è‡ªé€‚åº”å¼ºåº¦çš„è„¸éƒ¨å¢å¼º"""
        if self.face_enhancer is None:
            self.init_face_enhancer()
            
        if self.face_enhancer is None:
            return face_image, False
        
        try:
            # æ ¹æ®è´¨é‡åˆ†æ•°è°ƒæ•´å¢å¼ºå¼ºåº¦
            if quality_score > 0.8:
                strength = 0.5  # é«˜è´¨é‡å›¾åƒä½¿ç”¨è¾ƒä½å¼ºåº¦
            elif quality_score > 0.6:
                strength = 0.7  # ä¸­ç­‰è´¨é‡ä½¿ç”¨ä¸­ç­‰å¼ºåº¦
            else:
                strength = 0.9  # ä½è´¨é‡å›¾åƒä½¿ç”¨é«˜å¼ºåº¦
            
            # åº”ç”¨GFPGANå¢å¼º
            _, _, enhanced_face = self.face_enhancer.enhance(
                face_image, 
                has_aligned=False, 
                only_center_face=False, 
                paste_back=True,
                weight=strength
            )
            
            if enhanced_face is not None:
                # æ™ºèƒ½æ··åˆï¼šä¿ç•™ä¸€äº›åŸå§‹ç»†èŠ‚
                blend_factor = 0.8 if quality_score > 0.7 else 0.9
                final_result = cv2.addWeighted(
                    enhanced_face, blend_factor,
                    face_image, 1 - blend_factor,
                    0
                )
                
                logger.info(f"âœ… Enhanced face with adaptive strength: {strength:.2f}")
                return final_result, True
            else:
                return face_image, False
                
        except Exception as e:
            logger.warning(f"âš ï¸ Face enhancement failed: {e}")
            return face_image, False
    
    def advanced_face_swap(self, source_image: np.ndarray, target_image: np.ndarray) -> Tuple[np.ndarray, bool]:
        """é«˜çº§æ¢è„¸å¤„ç†æµç¨‹"""
        try:
            logger.info("ğŸ”„ Starting advanced face swap pipeline...")
            
            # 1. å¤šå°ºåº¦äººè„¸æ£€æµ‹
            logger.info("ğŸ” Multi-scale face detection...")
            source_faces = self.detect_faces_multi_scale(source_image)
            target_faces = self.detect_faces_multi_scale(target_image)
            
            if not source_faces:
                logger.warning("âš ï¸ No faces detected in source image")
                return target_image, False
                
            if not target_faces:
                logger.warning("âš ï¸ No faces detected in target image")
                return target_image, False
            
            # 2. é€‰æ‹©æœ€ä½³äººè„¸ï¼ˆæœ€å¤§é¢ç§¯ + æœ€é«˜ç½®ä¿¡åº¦ï¼‰
            def get_face_score(face):
                bbox = face.bbox
                area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
                return area * face.det_score
            
            source_face = max(source_faces, key=get_face_score)
            target_face = max(target_faces, key=get_face_score)
            
            logger.info(f"âœ… Selected source face (confidence: {source_face.det_score:.3f}, area: {get_face_score(source_face):.0f})")
            logger.info(f"âœ… Selected target face (confidence: {target_face.det_score:.3f}, area: {get_face_score(target_face):.0f})")
            
            # 3. å…‰ç…§æ ¡æ­£
            logger.info("ğŸŒŸ Applying lighting correction...")
            source_bbox = source_face.bbox.astype(int)
            source_face_region = source_image[source_bbox[1]:source_bbox[3], source_bbox[0]:source_bbox[2]]
            corrected_source = self.apply_lighting_correction(source_face_region, target_image)
            
            # 4. æ‰§è¡Œæ¢è„¸
            if self.face_swapper is None:
                self.init_face_swapper()
                
            if self.face_swapper is None:
                logger.error("âŒ Face swapper not available")
                return target_image, False
            
            logger.info("ğŸ”„ Performing face swap...")
            swapped_result = self.face_swapper.get(target_image, target_face, source_face, paste_back=True)
            
            if swapped_result is None:
                logger.warning("âš ï¸ Face swap failed")
                return target_image, False
            
            # 5. åŠ¨æ€æ··åˆ
            logger.info("ğŸ¨ Applying dynamic blending...")
            blend_ratio = self.calculate_dynamic_blend_ratio(source_face, target_face, source_image, target_image)
            
            # åˆ›å»ºæ¸å˜æ©ç 
            mask = self._create_gradient_mask(target_face, target_image.shape[:2])
            
            # åº”ç”¨åŠ¨æ€æ··åˆ
            for c in range(3):
                swapped_result[:, :, c] = (
                    swapped_result[:, :, c] * mask * blend_ratio +
                    target_image[:, :, c] * (1 - mask * blend_ratio)
                )
            
            # 6. åŒºåŸŸæ„ŸçŸ¥èåˆï¼ˆå¦‚æœæœ‰å…³é”®ç‚¹ï¼‰
            if hasattr(target_face, 'kps') and target_face.kps is not None:
                logger.info("âœ¨ Applying region-aware blending...")
                swapped_result = self.apply_region_aware_blending(
                    swapped_result, target_image, target_face.kps
                )
            
            # 7. é«˜çº§åå¤„ç†
            logger.info("ğŸ”§ Applying advanced post-processing...")
            
            # åŒè¾¹æ»¤æ³¢å‡å°‘ä¼ªå½±
            swapped_result = cv2.bilateralFilter(swapped_result, 9, 80, 80)
            
            # é”åŒ–å¢å¼ºç»†èŠ‚
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            sharpened = cv2.filter2D(swapped_result, -1, kernel)
            swapped_result = cv2.addWeighted(swapped_result, 0.8, sharpened, 0.2, 0)
            
            # 8. è‡ªé€‚åº”è„¸éƒ¨å¢å¼º
            logger.info("ğŸ”§ Applying adaptive face enhancement...")
            quality_score = min(source_face.det_score, target_face.det_score)
            enhanced_result, enhancement_success = self.enhance_face_with_adaptive_strength(
                swapped_result, quality_score
            )
            
            if enhancement_success:
                swapped_result = enhanced_result
            
            logger.info("âœ… Advanced face swap completed successfully")
            return swapped_result, True
            
        except Exception as e:
            logger.error(f"âŒ Advanced face swap failed: {e}")
            import traceback
            logger.error(f"ğŸ“ Traceback: {traceback.format_exc()}")
            return target_image, False
    
    def _create_gradient_mask(self, face, image_shape: Tuple[int, int]) -> np.ndarray:
        """åˆ›å»ºæ¸å˜æ©ç ç”¨äºè‡ªç„¶è¾¹ç•Œèåˆ"""
        h, w = image_shape
        mask = np.zeros((h, w), dtype=np.float32)
        
        bbox = face.bbox.astype(int)
        x1, y1, x2, y2 = bbox
        
        # æ‰©å±•è¾¹ç•Œæ¡†
        margin = int(min(x2 - x1, y2 - y1) * 0.1)
        x1 = max(0, x1 - margin)
        y1 = max(0, y1 - margin)
        x2 = min(w, x2 + margin)
        y2 = min(h, y2 + margin)
        
        # åˆ›å»ºæ¤­åœ†æ©ç 
        center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2
        radius_x, radius_y = (x2 - x1) // 2, (y2 - y1) // 2
        
        y_coords, x_coords = np.ogrid[:h, :w]
        ellipse_mask = ((x_coords - center_x) / radius_x) ** 2 + ((y_coords - center_y) / radius_y) ** 2
        
        # åˆ›å»ºæ¸å˜
        mask = np.where(ellipse_mask <= 1, 1.0, 0.0)
        mask = cv2.GaussianBlur(mask, (51, 51), 0)
        
        return mask

# å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
_face_swap_optimizer = None

def get_face_swap_optimizer() -> AdvancedFaceSwapOptimizer:
    """è·å–å…¨å±€æ¢è„¸ä¼˜åŒ–å™¨å®ä¾‹"""
    global _face_swap_optimizer
    if _face_swap_optimizer is None:
        _face_swap_optimizer = AdvancedFaceSwapOptimizer()
    return _face_swap_optimizer

def process_advanced_face_swap(source_image: np.ndarray, target_image: np.ndarray) -> Tuple[np.ndarray, bool]:
    """å¤„ç†é«˜çº§æ¢è„¸çš„ä¸»è¦æ¥å£"""
    optimizer = get_face_swap_optimizer()
    return optimizer.advanced_face_swap(source_image, target_image) 