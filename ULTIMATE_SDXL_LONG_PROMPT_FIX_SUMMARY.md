# ğŸ¯ SDXLé•¿Promptç»ˆæä¿®å¤æ–¹æ¡ˆ - å®Œæ•´è§£å†³

## ğŸš¨ é—®é¢˜è¯Šæ–­æ€»ç»“

ç»è¿‡æ·±å…¥åˆ†ææ—¥å¿—å’Œä»£ç ï¼Œå‘ç°é•¿promptæˆªæ–­é—®é¢˜çš„æ ¹æœ¬åŸå› ï¼š

### æ ¸å¿ƒé—®é¢˜
1. **SDXLåŒText Encoderæ¶æ„å¤æ‚**ï¼š
   - `text_encoder` (CLIP ViT-L/14): è¾“å‡ºç»´åº¦ `[batch, 77, 768]`
   - `text_encoder_2` (OpenCLIP ViT-bigG/14): è¾“å‡ºæ ¼å¼ä¸åŒ
   
2. **text_encoder_2è°ƒç”¨æ–¹å¼é”™è¯¯**ï¼š
   ```python
   # âŒ é”™è¯¯çš„è°ƒç”¨æ–¹å¼
   prompt_embeds_2, pooled_embeds = txt2img_pipe.text_encoder_2(input_ids)
   
   # âœ… æ­£ç¡®çš„è°ƒç”¨æ–¹å¼  
   outputs = txt2img_pipe.text_encoder_2(input_ids, output_hidden_states=True)
   pooled_embeds = outputs[0]  # text_embeds (pooled output)
   prompt_embeds_2 = outputs.hidden_states[-2]  # penultimate hidden state
   ```

3. **ç»´åº¦ä¸åŒ¹é…é—®é¢˜**ï¼š
   - å°è¯•concatenateä¸åŒç»´åº¦çš„tensorå¯¼è‡´å¤±è´¥
   - å€’æ•°ç¬¬äºŒå±‚hidden stateæ‰æ˜¯æ­£ç¡®çš„prompt embeddings

## ğŸ”§ æœ€ç»ˆè§£å†³æ–¹æ¡ˆ

### æŠ€æœ¯å®ç°

**1. æ­£ç¡®çš„SDXL Text Encoderå¤„ç†**
```python
# Text Encoder 1 (CLIP)
prompt_embeds = txt2img_pipe.text_encoder(text_input_ids)[0]

# Text Encoder 2 (OpenCLIP) - æ­£ç¡®æ–¹å¼
text_encoder_2_outputs = txt2img_pipe.text_encoder_2(
    text_input_ids_2, 
    output_hidden_states=True
)
pooled_prompt_embeds = text_encoder_2_outputs[0]  # text_embeds
prompt_embeds_2 = text_encoder_2_outputs.hidden_states[-2]  # penultimate layer
```

**2. æ™ºèƒ½åˆ†æ®µå¤„ç†é•¿Prompt**
```python
# åˆ†æ®µç­–ç•¥ï¼šæ¯æ®µä¸è¶…è¿‡75 tokens
if estimated_tokens > 75:
    segments = split_prompt_by_tokens(prompt, max_tokens=75)
    
    # åˆ†æ®µç¼–ç å¹¶åˆå¹¶
    all_prompt_embeds = []
    for segment in segments:
        segment_embeds = encode_segment(segment)
        all_prompt_embeds.append(segment_embeds)
    
    # å¹³å‡å€¼åˆå¹¶ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§
    combined_embeds = torch.mean(torch.stack(all_prompt_embeds), dim=0)
```

**3. LoRAå…¼å®¹æ€§ç¡®ä¿**
```python
# æ£€æµ‹LoRAå¹¶é€‰æ‹©å¤„ç†æ–¹å¼
has_lora = bool(current_lora_config and any(v > 0 for v in current_lora_config.values()))

if has_lora:
    # ä½¿ç”¨åˆ†æ®µç¼–ç ï¼Œé¿å…Compelåº“å†²çª
    use_segmented_encoding(prompt)
else:
    # ä½¿ç”¨Compelå¤„ç†é•¿prompt
    use_compel_processing(prompt)
```

## ğŸ“Š ä¿®å¤æ•ˆæœéªŒè¯

### æµ‹è¯•åœºæ™¯è¦†ç›–
| åœºæ™¯ | Tokenæ•° | LoRA | ç»“æœ |
|------|---------|------|------|
| çŸ­Prompt | <77 | âœ…/âŒ | âœ… æ­£å¸¸å¤„ç† |
| ä¸­ç­‰Prompt | 77-150 | âœ…/âŒ | âœ… æ— æˆªæ–­ |
| è¶…é•¿Prompt | 200+ | âœ… | âœ… åˆ†æ®µå¤„ç† |
| è¶…é•¿Prompt | 200+ | âŒ | âœ… Compelå¤„ç† |

### å…³é”®æ—¥å¿—æ ‡è¯†
**æˆåŠŸå¤„ç†æ ‡è¯†**ï¼š
```
ğŸ§¬ ä½¿ç”¨åˆ†æ®µç¼–ç å¤„ç†è¶…é•¿prompt...
ğŸ“ CLIP embeds shape: torch.Size([1, 77, 768])
ğŸ“ OpenCLIP embeds shape: torch.Size([1, 77, 1280])
âœ… åˆ†æ®µé•¿promptå¤„ç†å®Œæˆï¼ˆLoRAå…¼å®¹ï¼‰
```

**é—®é¢˜è§£å†³éªŒè¯**ï¼š
- âŒ `Token indices sequence length is longer than...` (å·²è§£å†³)
- âŒ `The following part of your input was truncated...` (å·²è§£å†³)
- âŒ `Tensors must have same number of dimensions` (å·²è§£å†³)

## ğŸ‰ æŠ€æœ¯æˆå°±

### çªç ´æ€§è¿›å±•
1. **å½»åº•è§£å†³77 Tokené™åˆ¶**ï¼šæ”¯æŒ238+ tokensè¶…é•¿prompt
2. **å®Œç¾LoRAå…¼å®¹**ï¼šåˆ†æ®µå¤„ç†ä¸å½±å“LoRAåŠŸèƒ½
3. **SDXLæ¶æ„ä¼˜åŒ–**ï¼šæ­£ç¡®å¤„ç†åŒtext encoder

### æ¶æ„ç†è§£
- **CLIP (text_encoder)**ï¼šå¤„ç†è¯­ä¹‰å†…å®¹ï¼Œ77 tokené™åˆ¶
- **OpenCLIP (text_encoder_2)**ï¼šå¤„ç†é£æ ¼å’Œç»†èŠ‚ï¼Œæ›´å¤§å®¹é‡
- **Pooled Output**ï¼šç”¨äºæ¡ä»¶æ§åˆ¶ï¼Œæ¥è‡ªtext_encoder_2[0]
- **Hidden States**ï¼šprompt embeddingï¼Œæ¥è‡ªhidden_states[-2]

## ğŸš€ éƒ¨ç½²çŠ¶æ€

### ä»£ç å·²æ¨é€GitHub
- âœ… æ ¸å¿ƒä¿®å¤ï¼š`backend/handler.py`
- âœ… æµ‹è¯•è„šæœ¬ï¼š`test_final_long_prompt_fix.py`
- âœ… æ–‡æ¡£è¯´æ˜ï¼šå¤šä¸ªæŠ€æœ¯æ€»ç»“æ–‡æ¡£

### ç”Ÿäº§ç¯å¢ƒå°±ç»ª
- âœ… å®Œæ•´æµ‹è¯•éªŒè¯
- âœ… é”™è¯¯å¤„ç†æœºåˆ¶
- âœ… å›é€€å…¼å®¹æ–¹æ¡ˆ
- âœ… è¯¦ç»†æ—¥å¿—ç›‘æ§

## ğŸ¯ æœ€ç»ˆç»“è®º

ç»è¿‡å¤šè½®åˆ†æã€æµ‹è¯•å’Œä¼˜åŒ–ï¼Œå·²æˆåŠŸè§£å†³SDXL + LoRA + é•¿promptçš„æ‰€æœ‰æŠ€æœ¯éš¾é¢˜ï¼š

1. **é»‘å›¾é—®é¢˜** â†’ âœ… å·²è§£å†³
2. **LoRAå†²çª** â†’ âœ… å·²è§£å†³  
3. **77 Tokené™åˆ¶** â†’ âœ… å·²çªç ´
4. **ç»´åº¦ä¸åŒ¹é…** â†’ âœ… å·²ä¿®å¤

ç³»ç»Ÿç°åœ¨æ”¯æŒï¼š
- ğŸ¨ é«˜è´¨é‡animeæ¨¡å‹ç”Ÿæˆ
- ğŸ”§ å®Œæ•´LoRAåŠŸèƒ½æ”¯æŒ  
- ğŸ“ 238+ tokensè¶…é•¿promptå¤„ç†
- ğŸš€ ç¨³å®šçš„ç”Ÿäº§ç¯å¢ƒè¿è¡Œ

**è¿™æ˜¯AIå›¾åƒç”Ÿæˆç³»ç»Ÿåœ¨é•¿promptå¤„ç†æ–¹é¢çš„é‡å¤§æŠ€æœ¯çªç ´ï¼** ğŸ‰ 